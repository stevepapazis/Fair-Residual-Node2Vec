{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4ef8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "facebook_path = pathlib.Path(\"./facebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e31d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "fb = nx.read_edgelist('./facebook_combined.txt', create_using=nx.Graph)\n",
    "\n",
    "fb_edges_f = open('./fb_edges.txt', 'w')\n",
    "fb_edges_f.write(str(fb.number_of_nodes())+'\\n')\n",
    "for edge in fb.edges():\n",
    "    fb_edges_f.write(edge[0]+'\\t'+edge[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a51c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set()\n",
    "nodes_per_file = dict()\n",
    "\n",
    "for filename in facebook_path.iterdir():\n",
    "    \n",
    "    if not filename.match(\"*.feat\"): continue\n",
    "    \n",
    "    id_,_ = filename.name.split(\".\")\n",
    "    ids.add(id_)\n",
    "    \n",
    "    nodes_per_file.setdefault(id_,[])\n",
    "    \n",
    "    for line in filename.read_text().splitlines():\n",
    "        nodes_per_file[id_].append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c43c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912 not found\n",
      "3437 not found\n",
      "3980 not found\n",
      "686 not found\n"
     ]
    }
   ],
   "source": [
    "for n in fb.nodes():\n",
    "    for id_ in nodes_per_file:\n",
    "        if n in nodes_per_file[id_]:\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{n} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e52b90f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 lacks gender information\n",
      "148 lacks gender information\n",
      "195 lacks gender information\n",
      "201 lacks gender information\n",
      "237 lacks gender information\n",
      "272 lacks gender information\n",
      "875 lacks gender information\n",
      "830 lacks gender information\n",
      "4001 lacks gender information\n",
      "4020 lacks gender information\n",
      "733 lacks gender information\n",
      "734 lacks gender information\n",
      "736 lacks gender information\n",
      "758 lacks gender information\n",
      "784 lacks gender information\n",
      "812 lacks gender information\n",
      "830 lacks gender information\n",
      "841 lacks gender information\n",
      "2668 lacks gender information\n",
      "2670 lacks gender information\n",
      "2687 lacks gender information\n",
      "2692 lacks gender information\n",
      "2746 lacks gender information\n",
      "2749 lacks gender information\n",
      "2865 lacks gender information\n",
      "2888 lacks gender information\n",
      "2908 lacks gender information\n",
      "2953 lacks gender information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009 lacks gender information\n",
      "3016 lacks gender information\n",
      "3113 lacks gender information\n",
      "3134 lacks gender information\n",
      "3170 lacks gender information\n",
      "3389 lacks gender information\n",
      "358 lacks gender information\n",
      "447 lacks gender information\n",
      "527 lacks gender information\n",
      "3456 lacks gender information\n",
      "3514 lacks gender information\n",
      "3545 lacks gender information\n",
      "3600 lacks gender information\n",
      "3611 lacks gender information\n",
      "3629 lacks gender information\n",
      "3630 lacks gender information\n",
      "3674 lacks gender information\n",
      "3675 lacks gender information\n",
      "3680 lacks gender information\n",
      "3708 lacks gender information\n",
      "3734 lacks gender information\n",
      "3737 lacks gender information\n",
      "3744 lacks gender information\n",
      "3760 lacks gender information\n",
      "3765 lacks gender information\n",
      "3811 lacks gender information\n",
      "3830 lacks gender information\n",
      "3834 lacks gender information\n",
      "3907 lacks gender information\n",
      "3924 lacks gender information\n",
      "3934 lacks gender information\n",
      "2008 lacks gender information\n",
      "2086 lacks gender information\n",
      "2092 lacks gender information\n",
      "2124 lacks gender information\n",
      "2139 lacks gender information\n",
      "2313 lacks gender information\n",
      "2398 lacks gender information\n",
      "2519 lacks gender information\n",
      "2520 lacks gender information\n",
      "601 lacks gender information\n",
      "602 lacks gender information\n",
      "607 lacks gender information\n",
      "638 lacks gender information\n",
      "668 lacks gender information\n",
      "674 lacks gender information\n",
      "991 lacks gender information\n",
      "1072 lacks gender information\n",
      "1080 lacks gender information\n",
      "1091 lacks gender information\n",
      "1101 lacks gender information\n",
      "1210 lacks gender information\n",
      "1268 lacks gender information\n",
      "1414 lacks gender information\n",
      "1524 lacks gender information\n",
      "601 lacks gender information\n",
      "1723 lacks gender information\n",
      "1856 lacks gender information\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nodes_with_genders = dict()\n",
    "noinfo_counter = 0\n",
    "\n",
    "\n",
    "for filename in facebook_path.iterdir():\n",
    "    if filename.match(\"*.featnames\"):\n",
    "        id = filename.name.split(\".\")[0]\n",
    "        \n",
    "        for s in filename.read_text().splitlines():\n",
    "            if \"feature 77\" in s:\n",
    "                location1 = int(s.split()[0])\n",
    "            if \"feature 78\" in s:\n",
    "                location2 = int(s.split()[0])\n",
    "        \n",
    "        egofeat = facebook_path/f\"{id}.egofeat\"\n",
    "        if egofeat.exists():\n",
    "            node = int(id)\n",
    "            line = egofeat.read_text()\n",
    "            gender1 = int(line.split()[location1])\n",
    "            gender2 = int(line.split()[location2]) \n",
    "            nodes_with_genders[node] = (1+gender1, 1+gender2)\n",
    "                \n",
    "        feat = facebook_path/f\"{id}.feat\"\n",
    "                \n",
    "        for line in feat.read_text().splitlines():\n",
    "            node = int(line.split()[0])\n",
    "            gender1 = int(line.split()[1:][location1])\n",
    "            gender2 = int(line.split()[1:][location2])\n",
    "            \n",
    "            if gender1 + gender2 != 1:\n",
    "                print(f\"{node} lacks gender information\")\n",
    "                noinfo_counter += 1\n",
    "                gender1 = np.random.randint(2)\n",
    "                gender2 = 1-gender1\n",
    "            \n",
    "            nodes_with_genders[node] = (1+gender1, 1+gender2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c2e45fa-6999-4c95-aba6-5fcd08acb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4039 entries to file\n"
     ]
    }
   ],
   "source": [
    "fb_genders_f = open('./fb_genders', 'w')\n",
    "fb_genders_f.write('2\\n')\n",
    "\n",
    "for node in nodes_with_genders:\n",
    "    _, gender2 = nodes_with_genders[node]\n",
    "    fb_genders_f.write(f\"{node}\\t{gender2}\\n\") \n",
    "    \n",
    "fb_genders_f.close()\n",
    "\n",
    "print(f\"Wrote {len(nodes_with_genders)} entries to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59c94a8a-aec5-499b-8853-bd1a22ca81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter = nx.Graph()\n",
    "\n",
    "# with open('Project/soc-political-retweet/soc-political-retweet.edges') as file:\n",
    "#     for line in file:\n",
    "#         words = line.split(',')\n",
    "#         twitter.add_edge(words[0], words[1])\n",
    "\n",
    "# twitter_edges_f = open('Project/snap-facebook-updated-master/fb_edges.txt', 'w')\n",
    "# twitter_edges_f.write(str(twitter.number_of_nodes())+'\\n')\n",
    "# for edge in twitter.edges():\n",
    "#     twitter_edges_f.write(edge[0]+'\\t'+edge[1]+'\\n')\n",
    "\n",
    "# with open('Project/soc-political-retweet/soc-political-retweet.node_labels') as file:\n",
    "#     for line in file:\n",
    "#         words = line.split(',')\n",
    "#         twitter.nodes[words[0]]['Politics'] = 'Right' if words[1].strip()=='1' else 'Left'\n",
    "\n",
    "# twitterf = open('Project/soc-political-retweet/twitter_politics', 'w')\n",
    "# twitterf.write('2\\n')\n",
    "# for node in twitter.nodes(data='Politics'):\n",
    "#     #if node[1]!=None:\n",
    "#     twitterf.write(node[0]+'\\t'+'0'+'\\n') if node[1]=='Right' else twitterf.write(node[0]+'\\t'+'1'+'\\n')\n",
    "#     #if node[1]=='Right':\n",
    "#     #    twitterf.write(node[0]+' '+'1'+'\\n')\n",
    "#     #else:\n",
    "#     #    twitterf.write(node[0]+' '+'2'+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
